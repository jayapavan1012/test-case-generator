# âœ… EC2 Deployment Checklist (VPN + Password Auth)

## ðŸš€ **Quick Deployment Steps**

### **Before You Start:**
- [ ] Connected to VPN
- [ ] Know your EC2 IP address
- [ ] Have username and password for EC2
- [ ] EC2 security group allows ports 22 (SSH) and 8082 (HTTP)

---

### **Step 1: Connect to EC2**
```bash
ssh username@your-ec2-ip
```
**Enter your password when prompted**

---

### **Step 2: Setup Environment**
```bash
# Update system
sudo apt-get update

# Install Python and dependencies
sudo apt-get install -y python3 python3-pip

# Install required packages
pip3 install --user flask llama-cpp-python psutil

# Add to PATH
export PATH="$HOME/.local/bin:$PATH"
echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.bashrc
```

---

### **Step 3: Create the Optimized Script**
```bash
# Create the script file
nano ~/codellama_test_generator.py
```

**Copy the entire optimized Python script from `deploy_manual_vpn.md` into this file**

---

### **Step 4: Start the Server**
```bash
# Make executable
chmod +x ~/codellama_test_generator.py

# Start server in background
nohup python3 ~/codellama_test_generator.py \
    --port 8082 \
    --host 0.0.0.0 \
    --model-path /path/to/your/model.gguf \
    > ~/codellama.log 2>&1 &

# Check if started
curl http://localhost:8082/health
```

---

### **Step 5: Initialize Model (if you have model file)**
```bash
curl -X POST http://localhost:8082/initialize-model \
  -H "Content-Type: application/json" \
  -d '{"model_path": "/path/to/your/model.gguf", "use_gpu": false}'
```

---

### **Step 6: Test from Your Local Machine**
```bash
# Test health
curl http://your-ec2-ip:8082/health

# Test generation
curl -X POST http://your-ec2-ip:8082/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "public class Test { public int add(int a, int b) { return a + b; } }", "className": "Test"}'
```

---

## ðŸŽ¯ **Performance Benefits You'll Get:**

âœ… **16 CPU threads** (2x more than before)  
âœ… **Memory monitoring** and optimization  
âœ… **Result caching** for instant repeated requests  
âœ… **Real-time performance metrics**  
âœ… **Graceful error handling**  
âœ… **10-45 second** generation times (vs 180+ timeout)  

---

## ðŸ” **Troubleshooting:**

### Server not starting?
```bash
# Check logs
tail -f ~/codellama.log

# Check if port is in use
sudo netstat -tlnp | grep 8082
```

### Memory issues?
```bash
# Check memory
curl http://localhost:8082/system-status

# Free memory if needed
sudo systemctl restart systemd-resolved
```

### Can't access from outside?
```bash
# Check firewall
sudo ufw status

# Open port if needed
sudo ufw allow 8082
```

---

## ðŸ“± **Quick Commands Reference:**

| **Action** | **Command** |
|------------|-------------|
| **Check Server** | `curl http://your-ec2-ip:8082/health` |
| **Monitor Memory** | `curl http://your-ec2-ip:8082/system-status` |
| **View Logs** | `tail -f ~/codellama.log` |
| **Restart Server** | `pkill -f python.*codellama && nohup python3 ~/codellama_test_generator.py --port 8082 > ~/codellama.log 2>&1 &` |

**Your optimized CodeLlama system is now ready for production! ðŸš€** 