# Server Configuration
server.port=8081
server.error.include-message=always
server.error.include-binding-errors=always

# Logging Configuration
logging.level.root=INFO
logging.level.com.mpokket=INFO
logging.level.org.springframework.cache=DEBUG
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n
logging.file.name=logs/test-generator.log
logging.file.max-size=10MB

# Application Configuration
spring.application.name=test-generator

# CodeLlama Configuration (using local test server)
llm.model-name=codellama-13b-instruct
llm.model-path=/home/adminuser/models/codellama-13b-instruct.Q4_K_M.gguf
llm.server-url=http://localhost:8082
llm.server-port=8082

# Model Parameters (optimized for CodeLlama)
llm.max-tokens=2048
llm.temperature=0.1
llm.top-p=0.95
llm.top-k=50
llm.stop-sequences=</s>,```

# Performance Settings (reduced for local testing)
llm.max-retries=3
llm.timeout-seconds=30
llm.enable-caching=true
llm.cache-size=100
llm.cache-expiration-minutes=60

# Context Management (CodeLlama supports 4K context)
llm.max-context-length=4096
llm.context-overlap-tokens=200

# LLM Service Configuration
logging.level.com.mpokket.testgenerator=INFO